{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSF9hcbx/pYOuMaaIqLkV0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ommakvana/BERT-MODEL/blob/main/Model_mix_linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMeEyWOnCcA9",
        "outputId": "126bdbcd-c572-46e4-9000-00ad8f47f0c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install newsapi-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDOyuPd7DUYc",
        "outputId": "892c6af8-0703-4f35-fe89-3f71e218f986"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: newsapi-python in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/dist-packages (from newsapi-python) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from datetime import timedelta, date\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "import statsmodels.api as sm\n",
        "import yfinance as yf\n",
        "import requests\n",
        "from newsapi import NewsApiClient  # Importing the NewsApiClient\n",
        "import warnings\n",
        "\n",
        "# Suppress specific warnings by their message\n",
        "warnings.filterwarnings(\"ignore\", message=\"A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"No supported index is available. Prediction results will be given with an integer index beginning at `start`.\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\")\n",
        "# warnings.filterwarnings(\"ignore\", message=\"['/content/drive/MyDrive/CustomZip.zip' has been unzipped into 'model_1'Unzipped files and directories: ['config.json', 'model.safetensors', 'training_args.bin'][*********************100%%**********************]  1 of 1 complete])\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Unzip the model\n",
        "zip_file_path = '/content/drive/MyDrive/CustomZip.zip'\n",
        "output_directory = 'model_1'\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_directory)\n",
        "\n",
        "print(f\"'{zip_file_path}' has been unzipped into '{output_directory}'\")\n",
        "unzipped_files = os.listdir(output_directory)\n",
        "print(\"Unzipped files and directories:\", unzipped_files)\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer for sentiment analysis\n",
        "model_1 = BertForSequenceClassification.from_pretrained(output_directory)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Initialize NewsAPI client\n",
        "newsapi = NewsApiClient(api_key='fd4bbea2de854d4f873b147acea59697')\n",
        "\n",
        "def get_company_news_titles(company_name):\n",
        "    query_params = {\n",
        "        'q': company_name,\n",
        "        'language': 'en',\n",
        "        'sort_by': 'publishedAt',\n",
        "        'page_size': 25\n",
        "    }\n",
        "    news_data = newsapi.get_everything(**query_params)\n",
        "    titles = [article['title'] for article in news_data['articles']]\n",
        "    return titles  # Corrected the return statement\n",
        "\n",
        "def get_stock_data(ticker):\n",
        "    start = '2000-01-01'\n",
        "    end = datetime.today().strftime('%Y-%m-%d')\n",
        "    stock_data = yf.download(ticker, start, end)\n",
        "\n",
        "    return stock_data\n",
        "\n",
        "def get_weighted_sentiment_score(company_name):\n",
        "    news_titles = get_company_news_titles(company_name)\n",
        "    inputs = tokenizer(news_titles, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model_1(**inputs)\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1).detach().numpy()\n",
        "    weights = np.linspace(1, 0, num=len(predictions))\n",
        "    weighted_average = np.average(predictions[:, 1], weights=weights)\n",
        "    return weighted_average\n",
        "\n",
        "def combine_data(stock_data, sentiment_score):\n",
        "    stock_data['Sentiment'] = sentiment_score\n",
        "    return stock_data\n",
        "\n",
        "def prepare_features(combined_data, what_to_predict):\n",
        "    combined_data['Close_1'] = combined_data[what_to_predict].shift(-1)\n",
        "    combined_data = combined_data.dropna()\n",
        "    features = combined_data[[what_to_predict, 'Sentiment']]\n",
        "    labels = combined_data['Close_1']\n",
        "    return train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "def predict_stock_prices(df, what_to_predict):\n",
        "    p, d, q = 5, 1, 0\n",
        "    seasonal_order = (1, 1, 0, 12)\n",
        "    model = sm.tsa.statespace.SARIMAX(df[what_to_predict], order=(p, d, q), seasonal_order=seasonal_order)\n",
        "    res = model.fit()\n",
        "    predicted_values = res.get_prediction(start=len(df)).predicted_mean\n",
        "    last_date = df.index[-1]\n",
        "    # Generate a new date range for the predicted values\n",
        "    forecast_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=len(predicted_values))\n",
        "    # Assign the new date range as the index to the predicted values DataFrame\n",
        "    predicted_values.index = forecast_dates\n",
        "    return predicted_values\n",
        "\n",
        "def unified_stock_prediction(company_name, ticker):\n",
        "    # Step 1: Get the weighted sentiment score\n",
        "    weighted_average = get_weighted_sentiment_score(company_name)\n",
        "\n",
        "    # Step 2: Get stock data\n",
        "    stock_data = get_stock_data(ticker)\n",
        "\n",
        "    # Step 3: Combine data\n",
        "    combined_data = combine_data(stock_data, weighted_average)\n",
        "\n",
        "\n",
        "    # Step 4: Prepare features\n",
        "    X_train, X_test, y_train, y_test = prepare_features(combined_data, 'Close')\n",
        "\n",
        "    # Step 5: Model training and prediction\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    mse = np.mean((predictions - y_test) ** 2)\n",
        "\n",
        "    # Step 6: Predict stock prices\n",
        "    predicted_values = predict_stock_prices(combined_data, 'Close')\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Company: {company_name}\")\n",
        "    print(\" \")\n",
        "    print(f\"Weighted Sentiment Score: {weighted_average:.2f}\")\n",
        "    print(\" \")\n",
        "    print(\"Predicted Stock Closing Prices:\",predicted_values)\n",
        "    print(\" \")\n",
        "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "\n",
        "# Example usage\n",
        "company_names = [\"Suzlon energy\"]\n",
        "tickers = [\"SUZLON.NS\"]\n",
        "\n",
        "for company_name, ticker in zip(company_names, tickers):\n",
        "    unified_stock_prediction(company_name, ticker)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnsLSgYDCchk",
        "outputId": "9a1afc2b-0cb9-4d87-dc52-6deb575dad3b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/CustomZip.zip' has been unzipped into 'model_1'\n",
            "Unzipped files and directories: ['config.json', 'model.safetensors', 'training_args.bin']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company: Suzlon energy\n",
            " \n",
            "Weighted Sentiment Score: 0.63\n",
            " \n",
            "Predicted Stock Closing Prices: 2024-05-31    46.372617\n",
            "Freq: D, dtype: float64\n",
            " \n",
            "Mean Squared Error: 15.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8X_qms5-M3BG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}